{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.32 s (started: 2023-01-06 14:07:41 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"!pip install --quiet -U watermark nb_black ipython-autotime\";\n                var nbb_formatted_code = \"!pip install --quiet -U watermark nb_black ipython-autotime\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --quiet -U watermark nb_black ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.31 s (started: 2023-01-06 14:07:43 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"!pip install --quiet -U tabulate torch ipywidgets numpy seaborn spacy textacy nltk\";\n                var nbb_formatted_code = \"!pip install --quiet -U tabulate torch ipywidgets numpy seaborn spacy textacy nltk\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --quiet -U tabulate torch ipywidgets numpy seaborn spacy textacy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "time: 862 µs (started: 2023-01-06 14:07:46 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"import watermark\\n%load_ext watermark\\n%load_ext autotime\\n%load_ext nb_black\\n%gui asyncio\";\n                var nbb_formatted_code = \"import watermark\\n\\n%load_ext watermark\\n%load_ext autotime\\n%load_ext nb_black\\n%gui asyncio\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import watermark\n",
    "%load_ext watermark\n",
    "%load_ext autotime\n",
    "%load_ext nb_black\n",
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 629 µs (started: 2023-01-06 14:07:46 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"import spacy\\nimport textacy\\nimport re\\nfrom spacy import displacy\\nfrom spacy.language import Language\\nfrom spacy.tokenizer import Tokenizer\\nfrom spacy.matcher import Matcher\\nfrom collections import Counter\";\n                var nbb_formatted_code = \"import spacy\\nimport textacy\\nimport re\\nfrom spacy import displacy\\nfrom spacy.language import Language\\nfrom spacy.tokenizer import Tokenizer\\nfrom spacy.matcher import Matcher\\nfrom collections import Counter\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import re\n",
    "from spacy import displacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.matcher import Matcher\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.8.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.0-56-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n",
      "spacy    : 3.4.4\n",
      "textacy  : 0.12.0\n",
      "sys      : 3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]\n",
      "re       : 2.2.1\n",
      "watermark: 2.3.1\n",
      "\n",
      "time: 8.14 ms (started: 2023-01-06 14:07:46 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"%watermark -i -n -v -m -iv\";\n                var nbb_formatted_code = \"%watermark -i -n -v -m -iv\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%watermark -i -n -v -m -iv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below just once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 µs (started: 2023-01-06 14:07:46 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"# !python -m spacy download en_core_web_sm\";\n                var nbb_formatted_code = \"# !python -m spacy download en_core_web_sm\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://realpython.com/natural-language-processing-spacy-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.05 s (started: 2023-01-06 14:07:47 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\ncustom_nlp = spacy.load(\\\"en_core_web_sm\\\")\";\n                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\ncustom_nlp = spacy.load(\\\"en_core_web_sm\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "custom_nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tutorial',\n",
       " 'is',\n",
       " 'about',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'in',\n",
       " 'spaCy',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.5 ms (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"introduction_doc = nlp(\\n    \\\"This tutorial is about Natural Language Processing in spaCy.\\\"\\n)\\ntype(introduction_doc)\\n\\n\\n[token.text for token in introduction_doc]\";\n                var nbb_formatted_code = \"introduction_doc = nlp(\\\"This tutorial is about Natural Language Processing in spaCy.\\\")\\ntype(introduction_doc)\\n\\n\\n[token.text for token in introduction_doc]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "introduction_doc = nlp(\n",
    "    \"This tutorial is about Natural Language Processing in spaCy.\"\n",
    ")\n",
    "type(introduction_doc)\n",
    "\n",
    "\n",
    "[token.text for token in introduction_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus Proto is a Python...\n",
      "He is interested in learning...\n",
      "time: 12.3 ms (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\nsentences = list(about_doc.sents)\\nlen(sentences)\\n\\nfor sentence in sentences:\\n    print(f\\\"{sentence[:5]}...\\\")\";\n                var nbb_formatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\nsentences = list(about_doc.sents)\\nlen(sentences)\\n\\nfor sentence in sentences:\\n    print(f\\\"{sentence[:5]}...\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "sentences = list(about_doc.sents)\n",
    "len(sentences)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus, can you, ...\n",
      "never mind, I forgot what I was saying.\n",
      "So, do you think we should ...\n",
      "time: 14.1 ms (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"ellipsis_text = (\\n    \\\"Gus, can you, ... never mind, I forgot\\\"\\n    \\\" what I was saying. So, do you think\\\"\\n    \\\" we should ...\\\"\\n)\\n\\n@Language.component(\\\"set_custom_boundaries\\\")\\ndef set_custom_boundaries(doc):\\n    \\\"\\\"\\\"Add support to use `...` as a delimiter for sentence detection\\\"\\\"\\\"\\n    for token in doc[:-1]:\\n        if token.text == \\\"...\\\":\\n            doc[token.i + 1].is_sent_start = True\\n    return doc\\ncustom_nlp.add_pipe(\\\"set_custom_boundaries\\\", before=\\\"parser\\\")\\ncustom_ellipsis_doc = custom_nlp(ellipsis_text)\\ncustom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\\nfor sentence in custom_ellipsis_sentences:\\n    print(sentence)\";\n                var nbb_formatted_code = \"ellipsis_text = (\\n    \\\"Gus, can you, ... never mind, I forgot\\\"\\n    \\\" what I was saying. So, do you think\\\"\\n    \\\" we should ...\\\"\\n)\\n\\n\\n@Language.component(\\\"set_custom_boundaries\\\")\\ndef set_custom_boundaries(doc):\\n    \\\"\\\"\\\"Add support to use `...` as a delimiter for sentence detection\\\"\\\"\\\"\\n    for token in doc[:-1]:\\n        if token.text == \\\"...\\\":\\n            doc[token.i + 1].is_sent_start = True\\n    return doc\\n\\n\\ncustom_nlp.add_pipe(\\\"set_custom_boundaries\\\", before=\\\"parser\\\")\\ncustom_ellipsis_doc = custom_nlp(ellipsis_text)\\ncustom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\\nfor sentence in custom_ellipsis_sentences:\\n    print(sentence)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ellipsis_text = (\n",
    "    \"Gus, can you, ... never mind, I forgot\"\n",
    "    \" what I was saying. So, do you think\"\n",
    "    \" we should ...\"\n",
    ")\n",
    "\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    \"\"\"Add support to use `...` as a delimiter for sentence detection\"\"\"\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "custom_nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "custom_ellipsis_doc = custom_nlp(ellipsis_text)\n",
    "custom_ellipsis_sentences = list(custom_ellipsis_doc.sents)\n",
    "for sentence in custom_ellipsis_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus 0\n",
      "Proto 4\n",
      "is 10\n",
      "a 13\n",
      "Python 15\n",
      "developer 22\n",
      "currently 32\n",
      "working 42\n",
      "for 50\n",
      "a 54\n",
      "London 56\n",
      "- 62\n",
      "based 63\n",
      "Fintech 69\n",
      "company 77\n",
      ". 84\n",
      "He 86\n",
      "is 89\n",
      "interested 92\n",
      "in 103\n",
      "learning 106\n",
      "Natural 115\n",
      "Language 123\n",
      "Processing 132\n",
      ". 142\n",
      "time: 10 ms (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\n\\nfor token in about_doc:\\n    print (token, token.idx)\";\n                var nbb_formatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\n\\nfor token in about_doc:\\n    print(token, token.idx)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "for token in about_doc:\n",
    "    print (token, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with Whitespace  Is Alphanumeric?Is Punctuation?   Is Stop Word?\n",
      "Gus                   True           False             False\n",
      "Proto                 True           False             False\n",
      "is                    True           False             True\n",
      "a                     True           False             True\n",
      "Python                True           False             False\n",
      "developer             True           False             False\n",
      "currently             True           False             False\n",
      "working               True           False             False\n",
      "for                   True           False             True\n",
      "a                     True           False             True\n",
      "London                True           False             False\n",
      "-                     False          True              False\n",
      "based                 True           False             False\n",
      "Fintech               True           False             False\n",
      "company               True           False             False\n",
      ".                     False          True              False\n",
      "He                    True           False             True\n",
      "is                    True           False             True\n",
      "interested            True           False             False\n",
      "in                    True           False             True\n",
      "learning              True           False             False\n",
      "Natural               True           False             False\n",
      "Language              True           False             False\n",
      "Processing            True           False             False\n",
      ".                     False          True              False\n",
      "time: 749 µs (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"print(\\n    f'{\\\"Text with Whitespace\\\":22}'\\n    f'{\\\"Is Alphanumeric?\\\":15}'\\n    f'{\\\"Is Punctuation?\\\":18}'\\n    f'{\\\"Is Stop Word?\\\"}'\\n)\\nfor token in about_doc:\\n    print(\\n        f\\\"{str(token.text_with_ws):22}\\\"\\n        f\\\"{str(token.is_alpha):15}\\\"\\n        f\\\"{str(token.is_punct):18}\\\"\\n        f\\\"{str(token.is_stop)}\\\"\\n    )\";\n                var nbb_formatted_code = \"print(\\n    f'{\\\"Text with Whitespace\\\":22}'\\n    f'{\\\"Is Alphanumeric?\\\":15}'\\n    f'{\\\"Is Punctuation?\\\":18}'\\n    f'{\\\"Is Stop Word?\\\"}'\\n)\\nfor token in about_doc:\\n    print(\\n        f\\\"{str(token.text_with_ws):22}\\\"\\n        f\\\"{str(token.is_alpha):15}\\\"\\n        f\\\"{str(token.is_punct):18}\\\"\\n        f\\\"{str(token.is_stop)}\\\"\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    f'{\"Text with Whitespace\":22}'\n",
    "    f'{\"Is Alphanumeric?\":15}'\n",
    "    f'{\"Is Punctuation?\":18}'\n",
    "    f'{\"Is Stop Word?\"}'\n",
    ")\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"{str(token.text_with_ws):22}\"\n",
    "        f\"{str(token.is_alpha):15}\"\n",
    "        f\"{str(token.is_punct):18}\"\n",
    "        f\"{str(token.is_stop)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['for', 'a', 'London', '@', 'based', 'Fintech', 'company']\n",
      "time: 555 ms (started: 2023-01-06 14:07:48 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"custom_nlp = spacy.load(\\\"en_core_web_sm\\\")\\nprefix_re = spacy.util.compile_prefix_regex(\\n    custom_nlp.Defaults.prefixes\\n)\\nsuffix_re = spacy.util.compile_suffix_regex(\\n    custom_nlp.Defaults.suffixes\\n)\\n\\ncustom_infixes = [r\\\"@\\\"]\\n\\ninfix_re = spacy.util.compile_infix_regex(\\n    list(custom_nlp.Defaults.infixes) + custom_infixes\\n)\\n\\ncustom_nlp.tokenizer = Tokenizer(\\n    nlp.vocab,\\n    prefix_search=prefix_re.search,\\n    suffix_search=suffix_re.search,\\n    infix_finditer=infix_re.finditer,\\n    token_match=None,\\n)\\n\\ncustom_about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London@based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\n\\ncustom_tokenizer_about_doc = custom_nlp(custom_about_text)\\nprint([token.text for token in custom_tokenizer_about_doc[8:15]])\";\n                var nbb_formatted_code = \"custom_nlp = spacy.load(\\\"en_core_web_sm\\\")\\nprefix_re = spacy.util.compile_prefix_regex(custom_nlp.Defaults.prefixes)\\nsuffix_re = spacy.util.compile_suffix_regex(custom_nlp.Defaults.suffixes)\\n\\ncustom_infixes = [r\\\"@\\\"]\\n\\ninfix_re = spacy.util.compile_infix_regex(\\n    list(custom_nlp.Defaults.infixes) + custom_infixes\\n)\\n\\ncustom_nlp.tokenizer = Tokenizer(\\n    nlp.vocab,\\n    prefix_search=prefix_re.search,\\n    suffix_search=suffix_re.search,\\n    infix_finditer=infix_re.finditer,\\n    token_match=None,\\n)\\n\\ncustom_about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London@based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\n\\ncustom_tokenizer_about_doc = custom_nlp(custom_about_text)\\nprint([token.text for token in custom_tokenizer_about_doc[8:15]])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_nlp = spacy.load(\"en_core_web_sm\")\n",
    "prefix_re = spacy.util.compile_prefix_regex(\n",
    "    custom_nlp.Defaults.prefixes\n",
    ")\n",
    "suffix_re = spacy.util.compile_suffix_regex(\n",
    "    custom_nlp.Defaults.suffixes\n",
    ")\n",
    "\n",
    "custom_infixes = [r\"@\"]\n",
    "\n",
    "infix_re = spacy.util.compile_infix_regex(\n",
    "    list(custom_nlp.Defaults.infixes) + custom_infixes\n",
    ")\n",
    "\n",
    "custom_nlp.tokenizer = Tokenizer(\n",
    "    nlp.vocab,\n",
    "    prefix_search=prefix_re.search,\n",
    "    suffix_search=suffix_re.search,\n",
    "    infix_finditer=infix_re.finditer,\n",
    "    token_match=None,\n",
    ")\n",
    "\n",
    "custom_about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London@based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "custom_tokenizer_about_doc = custom_nlp(custom_about_text)\n",
    "print([token.text for token in custom_tokenizer_about_doc[8:15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "below\n",
      "had\n",
      "neither\n",
      "a\n",
      "nevertheless\n",
      "will\n",
      "third\n",
      "whatever\n",
      "‘re\n",
      "been\n",
      "time: 489 µs (started: 2023-01-06 14:07:49 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\\nlen(spacy_stopwords)\\n\\nfor stop_word in list(spacy_stopwords)[:10]:\\n    print(stop_word)\";\n                var nbb_formatted_code = \"spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\\nlen(spacy_stopwords)\\n\\nfor stop_word in list(spacy_stopwords)[:10]:\\n    print(stop_word)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "len(spacy_stopwords)\n",
    "\n",
    "for stop_word in list(spacy_stopwords)[:10]:\n",
    "    print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gus, Proto, Python, developer, currently, working, London, -, based, Fintech, company, ., interested, learning, Natural, Language, Processing, .]\n",
      "time: 519 ms (started: 2023-01-06 14:07:49 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"custom_about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nabout_doc = nlp(custom_about_text)\\nprint([token for token in about_doc if not token.is_stop])\";\n                var nbb_formatted_code = \"custom_about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\\nabout_doc = nlp(custom_about_text)\\nprint([token for token in about_doc if not token.is_stop])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "about_doc = nlp(custom_about_text)\n",
    "print([token for token in about_doc if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  is : be\n",
      "                  He : he\n",
      "               keeps : keep\n",
      "          organizing : organize\n",
      "             meetups : meetup\n",
      "               talks : talk\n",
      "time: 13.4 ms (started: 2023-01-06 14:07:49 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"conference_help_text = (\\n    \\\"Gus is helping organize a developer\\\"\\n    \\\" conference on Applications of Natural Language\\\"\\n    \\\" Processing. He keeps organizing local Python meetups\\\"\\n    \\\" and several internal talks at his workplace.\\\"\\n)\\nconference_help_doc = nlp(conference_help_text)\\nfor token in conference_help_doc:\\n    if str(token) != str(token.lemma_):\\n        print(f\\\"{str(token):>20} : {str(token.lemma_)}\\\")\";\n                var nbb_formatted_code = \"conference_help_text = (\\n    \\\"Gus is helping organize a developer\\\"\\n    \\\" conference on Applications of Natural Language\\\"\\n    \\\" Processing. He keeps organizing local Python meetups\\\"\\n    \\\" and several internal talks at his workplace.\\\"\\n)\\nconference_help_doc = nlp(conference_help_text)\\nfor token in conference_help_doc:\\n    if str(token) != str(token.lemma_):\\n        print(f\\\"{str(token):>20} : {str(token.lemma_)}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conference_help_text = (\n",
    "    \"Gus is helping organize a developer\"\n",
    "    \" conference on Applications of Natural Language\"\n",
    "    \" Processing. He keeps organizing local Python meetups\"\n",
    "    \" and several internal talks at his workplace.\"\n",
    ")\n",
    "conference_help_doc = nlp(conference_help_text)\n",
    "for token in conference_help_doc:\n",
    "    if str(token) != str(token.lemma_):\n",
    "        print(f\"{str(token):>20} : {str(token.lemma_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]\n",
      "time: 28.2 ms (started: 2023-01-06 14:07:49 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"complete_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech company. He is\\\"\\n    \\\" interested in learning Natural Language Processing.\\\"\\n    \\\" There is a developer conference happening on 21 July\\\"\\n    ' 2019 in London. It is titled \\\"Applications of Natural'\\n    ' Language Processing\\\". There is a helpline number'\\n    \\\" available at +44-1234567891. Gus is helping organize it.\\\"\\n    \\\" He keeps organizing local Python meetups and several\\\"\\n    \\\" internal talks at his workplace. Gus is also presenting\\\"\\n    ' a talk. The talk will introduce the reader about \\\"Use'\\n    ' cases of Natural Language Processing in Fintech\\\".'\\n    \\\" Apart from his work, he is very passionate about music.\\\"\\n    \\\" Gus is learning to play the Piano. He has enrolled\\\"\\n    \\\" himself in the weekend batch of Great Piano Academy.\\\"\\n    \\\" Great Piano Academy is situated in Mayfair or the City\\\"\\n    \\\" of London and has world-class piano instructors.\\\"\\n)\\ncomplete_doc = nlp(complete_text)\\n\\nwords = [\\n    token.text\\n    for token in complete_doc\\n    if not token.is_stop and not token.is_punct\\n]\\n\\nprint(Counter(words).most_common(5))\";\n                var nbb_formatted_code = \"complete_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech company. He is\\\"\\n    \\\" interested in learning Natural Language Processing.\\\"\\n    \\\" There is a developer conference happening on 21 July\\\"\\n    ' 2019 in London. It is titled \\\"Applications of Natural'\\n    ' Language Processing\\\". There is a helpline number'\\n    \\\" available at +44-1234567891. Gus is helping organize it.\\\"\\n    \\\" He keeps organizing local Python meetups and several\\\"\\n    \\\" internal talks at his workplace. Gus is also presenting\\\"\\n    ' a talk. The talk will introduce the reader about \\\"Use'\\n    ' cases of Natural Language Processing in Fintech\\\".'\\n    \\\" Apart from his work, he is very passionate about music.\\\"\\n    \\\" Gus is learning to play the Piano. He has enrolled\\\"\\n    \\\" himself in the weekend batch of Great Piano Academy.\\\"\\n    \\\" Great Piano Academy is situated in Mayfair or the City\\\"\\n    \\\" of London and has world-class piano instructors.\\\"\\n)\\ncomplete_doc = nlp(complete_text)\\n\\nwords = [\\n    token.text for token in complete_doc if not token.is_stop and not token.is_punct\\n]\\n\\nprint(Counter(words).most_common(5))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech company. He is\"\n",
    "    \" interested in learning Natural Language Processing.\"\n",
    "    \" There is a developer conference happening on 21 July\"\n",
    "    ' 2019 in London. It is titled \"Applications of Natural'\n",
    "    ' Language Processing\". There is a helpline number'\n",
    "    \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "    \" He keeps organizing local Python meetups and several\"\n",
    "    \" internal talks at his workplace. Gus is also presenting\"\n",
    "    ' a talk. The talk will introduce the reader about \"Use'\n",
    "    ' cases of Natural Language Processing in Fintech\".'\n",
    "    \" Apart from his work, he is very passionate about music.\"\n",
    "    \" Gus is learning to play the Piano. He has enrolled\"\n",
    "    \" himself in the weekend batch of Great Piano Academy.\"\n",
    "    \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "    \" of London and has world-class piano instructors.\"\n",
    ")\n",
    "complete_doc = nlp(complete_text)\n",
    "\n",
    "words = [\n",
    "    token.text\n",
    "    for token in complete_doc\n",
    "    if not token.is_stop and not token.is_punct\n",
    "]\n",
    "\n",
    "print(Counter(words).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 10), ('a', 5), ('in', 5), ('Gus', 4), ('of', 4)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.36 ms (started: 2023-01-06 14:07:49 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"Counter(\\n    [token.text for token in complete_doc if not token.is_punct]\\n).most_common(5)\";\n                var nbb_formatted_code = \"Counter([token.text for token in complete_doc if not token.is_punct]).most_common(5)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Counter(\n",
    "    [token.text for token in complete_doc if not token.is_punct]\n",
    ").most_common(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKEN: Gus\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: Proto\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "TAG: VBZ        POS: AUX\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: a\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: Python\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: developer\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: currently\n",
      "=====\n",
      "TAG: RB         POS: ADV\n",
      "EXPLANATION: adverb\n",
      "\n",
      "TOKEN: working\n",
      "=====\n",
      "TAG: VBG        POS: VERB\n",
      "EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "TOKEN: for\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: a\n",
      "=====\n",
      "TAG: DT         POS: DET\n",
      "EXPLANATION: determiner\n",
      "\n",
      "TOKEN: London\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: -\n",
      "=====\n",
      "TAG: HYPH       POS: PUNCT\n",
      "EXPLANATION: punctuation mark, hyphen\n",
      "\n",
      "TOKEN: based\n",
      "=====\n",
      "TAG: VBN        POS: VERB\n",
      "EXPLANATION: verb, past participle\n",
      "\n",
      "TOKEN: Fintech\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: company\n",
      "=====\n",
      "TAG: NN         POS: NOUN\n",
      "EXPLANATION: noun, singular or mass\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "\n",
      "TOKEN: He\n",
      "=====\n",
      "TAG: PRP        POS: PRON\n",
      "EXPLANATION: pronoun, personal\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "TAG: VBZ        POS: AUX\n",
      "EXPLANATION: verb, 3rd person singular present\n",
      "\n",
      "TOKEN: interested\n",
      "=====\n",
      "TAG: JJ         POS: ADJ\n",
      "EXPLANATION: adjective (English), other noun-modifier (Chinese)\n",
      "\n",
      "TOKEN: in\n",
      "=====\n",
      "TAG: IN         POS: ADP\n",
      "EXPLANATION: conjunction, subordinating or preposition\n",
      "\n",
      "TOKEN: learning\n",
      "=====\n",
      "TAG: VBG        POS: VERB\n",
      "EXPLANATION: verb, gerund or present participle\n",
      "\n",
      "TOKEN: Natural\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: Language\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: Processing\n",
      "=====\n",
      "TAG: NNP        POS: PROPN\n",
      "EXPLANATION: noun, proper singular\n",
      "\n",
      "TOKEN: .\n",
      "=====\n",
      "TAG: .          POS: PUNCT\n",
      "EXPLANATION: punctuation mark, sentence closer\n",
      "time: 9.03 ms (started: 2023-01-06 14:07:50 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\nfor token in about_doc:\\n    print(\\n        f\\\"\\\"\\\"\\nTOKEN: {str(token)}\\n=====\\nTAG: {str(token.tag_):10} POS: {token.pos_}\\nEXPLANATION: {spacy.explain(token.tag_)}\\\"\\\"\\\"\\n    )\";\n                var nbb_formatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\nfor token in about_doc:\\n    print(\\n        f\\\"\\\"\\\"\\nTOKEN: {str(token)}\\n=====\\nTAG: {str(token.tag_):10} POS: {token.pos_}\\nEXPLANATION: {spacy.explain(token.tag_)}\\\"\\\"\\\"\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "for token in about_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {str(token)}\n",
    "=====\n",
    "TAG: {str(token.tag_):10} POS: {token.pos_}\n",
    "EXPLANATION: {spacy.explain(token.tag_)}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[developer, company]\n",
      "[interested]\n",
      "time: 489 µs (started: 2023-01-06 14:07:50 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"nouns = []\\nadjectives = []\\nfor token in about_doc:\\n    if token.pos_ == \\\"NOUN\\\":\\n        nouns.append(token)\\n    if token.pos_ == \\\"ADJ\\\":\\n        adjectives.append(token)\\n\\nprint(nouns)\\nprint(adjectives)\";\n                var nbb_formatted_code = \"nouns = []\\nadjectives = []\\nfor token in about_doc:\\n    if token.pos_ == \\\"NOUN\\\":\\n        nouns.append(token)\\n    if token.pos_ == \\\"ADJ\\\":\\n        adjectives.append(token)\\n\\nprint(nouns)\\nprint(adjectives)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nouns = []\n",
    "adjectives = []\n",
    "for token in about_doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == \"ADJ\":\n",
    "        adjectives.append(token)\n",
    "\n",
    "print(nouns)\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1318e7ce5a544288906e2d0a307d7ea8-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1318e7ce5a544288906e2d0a307d7ea8-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1318e7ce5a544288906e2d0a307d7ea8-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 521 ms (started: 2023-01-06 14:07:50 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\nabout_interest_text = (\\n    \\\"He is interested in learning Natural Language Processing.\\\"\\n)\\nabout_interest_doc = nlp(about_interest_text)\\ndisplacy.render(about_interest_doc, style=\\\"dep\\\")\";\n                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\n\\nabout_interest_text = \\\"He is interested in learning Natural Language Processing.\\\"\\nabout_interest_doc = nlp(about_interest_text)\\ndisplacy.render(about_interest_doc, style=\\\"dep\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "about_interest_text = (\n",
    "    \"He is interested in learning Natural Language Processing.\"\n",
    ")\n",
    "about_interest_doc = nlp(about_interest_text)\n",
    "displacy.render(about_interest_doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gus',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'developer',\n",
       " 'currently',\n",
       " 'work',\n",
       " 'london',\n",
       " 'base',\n",
       " 'fintech',\n",
       " 'company',\n",
       " 'interested',\n",
       " 'learn',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'developer',\n",
       " 'conference',\n",
       " 'happen',\n",
       " '21',\n",
       " 'july',\n",
       " '2019',\n",
       " 'london',\n",
       " 'title',\n",
       " 'applications',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'helpline',\n",
       " 'number',\n",
       " 'available',\n",
       " '+44',\n",
       " '1234567891',\n",
       " 'gus',\n",
       " 'helping',\n",
       " 'organize',\n",
       " 'keep',\n",
       " 'organize',\n",
       " 'local',\n",
       " 'python',\n",
       " 'meetup',\n",
       " 'internal',\n",
       " 'talk',\n",
       " 'workplace',\n",
       " 'gus',\n",
       " 'present',\n",
       " 'talk',\n",
       " 'talk',\n",
       " 'introduce',\n",
       " 'reader',\n",
       " 'use',\n",
       " 'case',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'fintech',\n",
       " 'apart',\n",
       " 'work',\n",
       " 'passionate',\n",
       " 'music',\n",
       " 'gus',\n",
       " 'learn',\n",
       " 'play',\n",
       " 'piano',\n",
       " 'enrol',\n",
       " 'weekend',\n",
       " 'batch',\n",
       " 'great',\n",
       " 'piano',\n",
       " 'academy',\n",
       " 'great',\n",
       " 'piano',\n",
       " 'academy',\n",
       " 'situate',\n",
       " 'mayfair',\n",
       " 'city',\n",
       " 'london',\n",
       " 'world',\n",
       " 'class',\n",
       " 'piano',\n",
       " 'instructor']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 662 ms (started: 2023-01-06 14:07:50 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\ncomplete_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech company. He is\\\"\\n    \\\" interested in learning Natural Language Processing.\\\"\\n    \\\" There is a developer conference happening on 21 July\\\"\\n    ' 2019 in London. It is titled \\\"Applications of Natural'\\n    ' Language Processing\\\". There is a helpline number'\\n    \\\" available at +44-1234567891. Gus is helping organize it.\\\"\\n    \\\" He keeps organizing local Python meetups and several\\\"\\n    \\\" internal talks at his workplace. Gus is also presenting\\\"\\n    ' a talk. The talk will introduce the reader about \\\"Use'\\n    ' cases of Natural Language Processing in Fintech\\\".'\\n    \\\" Apart from his work, he is very passionate about music.\\\"\\n    \\\" Gus is learning to play the Piano. He has enrolled\\\"\\n    \\\" himself in the weekend batch of Great Piano Academy.\\\"\\n    \\\" Great Piano Academy is situated in Mayfair or the City\\\"\\n    \\\" of London and has world-class piano instructors.\\\"\\n)\\ncomplete_doc = nlp(complete_text)\\ndef is_token_allowed(token):\\n    return bool(\\n        token\\n        and str(token).strip()\\n        and not token.is_stop\\n        and not token.is_punct\\n    )\\n\\ndef preprocess_token(token):\\n    return token.lemma_.strip().lower()\\n\\ncomplete_filtered_tokens = [\\n    preprocess_token(token)\\n    for token in complete_doc\\n    if is_token_allowed(token)\\n]\\n\\ncomplete_filtered_tokens\";\n                var nbb_formatted_code = \"nlp = spacy.load(\\\"en_core_web_sm\\\")\\ncomplete_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech company. He is\\\"\\n    \\\" interested in learning Natural Language Processing.\\\"\\n    \\\" There is a developer conference happening on 21 July\\\"\\n    ' 2019 in London. It is titled \\\"Applications of Natural'\\n    ' Language Processing\\\". There is a helpline number'\\n    \\\" available at +44-1234567891. Gus is helping organize it.\\\"\\n    \\\" He keeps organizing local Python meetups and several\\\"\\n    \\\" internal talks at his workplace. Gus is also presenting\\\"\\n    ' a talk. The talk will introduce the reader about \\\"Use'\\n    ' cases of Natural Language Processing in Fintech\\\".'\\n    \\\" Apart from his work, he is very passionate about music.\\\"\\n    \\\" Gus is learning to play the Piano. He has enrolled\\\"\\n    \\\" himself in the weekend batch of Great Piano Academy.\\\"\\n    \\\" Great Piano Academy is situated in Mayfair or the City\\\"\\n    \\\" of London and has world-class piano instructors.\\\"\\n)\\ncomplete_doc = nlp(complete_text)\\n\\n\\ndef is_token_allowed(token):\\n    return bool(\\n        token and str(token).strip() and not token.is_stop and not token.is_punct\\n    )\\n\\n\\ndef preprocess_token(token):\\n    return token.lemma_.strip().lower()\\n\\n\\ncomplete_filtered_tokens = [\\n    preprocess_token(token) for token in complete_doc if is_token_allowed(token)\\n]\\n\\ncomplete_filtered_tokens\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "complete_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech company. He is\"\n",
    "    \" interested in learning Natural Language Processing.\"\n",
    "    \" There is a developer conference happening on 21 July\"\n",
    "    ' 2019 in London. It is titled \"Applications of Natural'\n",
    "    ' Language Processing\". There is a helpline number'\n",
    "    \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "    \" He keeps organizing local Python meetups and several\"\n",
    "    \" internal talks at his workplace. Gus is also presenting\"\n",
    "    ' a talk. The talk will introduce the reader about \"Use'\n",
    "    ' cases of Natural Language Processing in Fintech\".'\n",
    "    \" Apart from his work, he is very passionate about music.\"\n",
    "    \" Gus is learning to play the Piano. He has enrolled\"\n",
    "    \" himself in the weekend batch of Great Piano Academy.\"\n",
    "    \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "    \" of London and has world-class piano instructors.\"\n",
    ")\n",
    "complete_doc = nlp(complete_text)\n",
    "def is_token_allowed(token):\n",
    "    return bool(\n",
    "        token\n",
    "        and str(token).strip()\n",
    "        and not token.is_stop\n",
    "        and not token.is_punct\n",
    "    )\n",
    "\n",
    "def preprocess_token(token):\n",
    "    return token.lemma_.strip().lower()\n",
    "\n",
    "complete_filtered_tokens = [\n",
    "    preprocess_token(token)\n",
    "    for token in complete_doc\n",
    "    if is_token_allowed(token)\n",
    "]\n",
    "\n",
    "complete_filtered_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interactive matcher: \n",
    "https://demos.explosion.ai/matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gus Proto'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.9 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\n\\n# from spacy.matcher import Matcher\\nmatcher = Matcher(nlp.vocab)\\n\\ndef extract_full_name(nlp_doc):\\n    pattern = [{\\\"POS\\\": \\\"PROPN\\\"}, {\\\"POS\\\": \\\"PROPN\\\"}]\\n    matcher.add(\\\"FULL_NAME\\\", [pattern])\\n    matches = matcher(nlp_doc)\\n    for _, start, end in matches:\\n        span = nlp_doc[start:end]\\n        yield span.text\\n\\nnext(extract_full_name(about_doc))\";\n                var nbb_formatted_code = \"about_text = (\\n    \\\"Gus Proto is a Python developer currently\\\"\\n    \\\" working for a London-based Fintech\\\"\\n    \\\" company. He is interested in learning\\\"\\n    \\\" Natural Language Processing.\\\"\\n)\\nabout_doc = nlp(about_text)\\n\\n# from spacy.matcher import Matcher\\nmatcher = Matcher(nlp.vocab)\\n\\n\\ndef extract_full_name(nlp_doc):\\n    pattern = [{\\\"POS\\\": \\\"PROPN\\\"}, {\\\"POS\\\": \\\"PROPN\\\"}]\\n    matcher.add(\\\"FULL_NAME\\\", [pattern])\\n    matches = matcher(nlp_doc)\\n    for _, start, end in matches:\\n        span = nlp_doc[start:end]\\n        yield span.text\\n\\n\\nnext(extract_full_name(about_doc))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "# from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_full_name(nlp_doc):\n",
    "    pattern = [{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]\n",
    "    matcher.add(\"FULL_NAME\", [pattern])\n",
    "    matches = matcher(nlp_doc)\n",
    "    for _, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        yield span.text\n",
    "\n",
    "next(extract_full_name(about_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.4 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"conference_org_text = (\\\"There is a developer conference\\\"\\n    \\\" happening on 21 July 2019 in London. It is titled\\\"\\n    ' \\\"Applications of Natural Language Processing\\\".'\\n    \\\" There is a helpline number available\\\"\\n    \\\" at (123) 456-7891\\\")\\n\\n\\ndef extract_phone_number(nlp_doc):\\n    pattern = [\\n        {\\\"ORTH\\\": \\\"(\\\"},\\n        {\\\"SHAPE\\\": \\\"ddd\\\"},\\n        {\\\"ORTH\\\": \\\")\\\"},\\n        {\\\"SHAPE\\\": \\\"ddd\\\"},\\n        {\\\"ORTH\\\": \\\"-\\\", \\\"OP\\\": \\\"?\\\"},\\n        {\\\"SHAPE\\\": \\\"dddd\\\"},\\n    ]\\n    matcher.add(\\\"PHONE_NUMBER\\\", [pattern])\\n    matches = matcher(nlp_doc)\\n    for match_id, start, end in matches:\\n        span = nlp_doc[start:end]\\n        return span.text\\n\\n\\nconference_org_doc = nlp(conference_org_text)\\nextract_phone_number(conference_org_doc)\";\n                var nbb_formatted_code = \"conference_org_text = (\\n    \\\"There is a developer conference\\\"\\n    \\\" happening on 21 July 2019 in London. It is titled\\\"\\n    ' \\\"Applications of Natural Language Processing\\\".'\\n    \\\" There is a helpline number available\\\"\\n    \\\" at (123) 456-7891\\\"\\n)\\n\\n\\ndef extract_phone_number(nlp_doc):\\n    pattern = [\\n        {\\\"ORTH\\\": \\\"(\\\"},\\n        {\\\"SHAPE\\\": \\\"ddd\\\"},\\n        {\\\"ORTH\\\": \\\")\\\"},\\n        {\\\"SHAPE\\\": \\\"ddd\\\"},\\n        {\\\"ORTH\\\": \\\"-\\\", \\\"OP\\\": \\\"?\\\"},\\n        {\\\"SHAPE\\\": \\\"dddd\\\"},\\n    ]\\n    matcher.add(\\\"PHONE_NUMBER\\\", [pattern])\\n    matches = matcher(nlp_doc)\\n    for match_id, start, end in matches:\\n        span = nlp_doc[start:end]\\n        return span.text\\n\\n\\nconference_org_doc = nlp(conference_org_text)\\nextract_phone_number(conference_org_doc)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conference_org_text = (\"There is a developer conference\"\n",
    "    \" happening on 21 July 2019 in London. It is titled\"\n",
    "    ' \"Applications of Natural Language Processing\".'\n",
    "    \" There is a helpline number available\"\n",
    "    \" at (123) 456-7891\")\n",
    "\n",
    "\n",
    "def extract_phone_number(nlp_doc):\n",
    "    pattern = [\n",
    "        {\"ORTH\": \"(\"},\n",
    "        {\"SHAPE\": \"ddd\"},\n",
    "        {\"ORTH\": \")\"},\n",
    "        {\"SHAPE\": \"ddd\"},\n",
    "        {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
    "        {\"SHAPE\": \"dddd\"},\n",
    "    ]\n",
    "    matcher.add(\"PHONE_NUMBER\", [pattern])\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text\n",
    "\n",
    "\n",
    "conference_org_doc = nlp(conference_org_text)\n",
    "extract_phone_number(conference_org_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOKEN: Gus\n",
      "=====\n",
      "token.tag_ = 'NNP'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'nsubj'\n",
      "\n",
      "TOKEN: is\n",
      "=====\n",
      "token.tag_ = 'VBZ'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'aux'\n",
      "\n",
      "TOKEN: learning\n",
      "=====\n",
      "token.tag_ = 'VBG'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'ROOT'\n",
      "\n",
      "TOKEN: piano\n",
      "=====\n",
      "token.tag_ = 'NN'\n",
      "token.head.text = 'learning'\n",
      "token.dep_ = 'dobj'\n",
      "time: 6.4 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"piano_text = \\\"Gus is learning piano\\\"\\npiano_doc = nlp(piano_text)\\nfor token in piano_doc:\\n    print(\\n        f\\\"\\\"\\\"\\nTOKEN: {token.text}\\n=====\\n{token.tag_ = }\\n{token.head.text = }\\n{token.dep_ = }\\\"\\\"\\\"\\n    )\";\n                var nbb_formatted_code = \"piano_text = \\\"Gus is learning piano\\\"\\npiano_doc = nlp(piano_text)\\nfor token in piano_doc:\\n    print(\\n        f\\\"\\\"\\\"\\nTOKEN: {token.text}\\n=====\\n{token.tag_ = }\\n{token.head.text = }\\n{token.dep_ = }\\\"\\\"\\\"\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "piano_text = \"Gus is learning piano\"\n",
    "piano_doc = nlp(piano_text)\n",
    "for token in piano_doc:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "TOKEN: {token.text}\n",
    "=====\n",
    "{token.tag_ = }\n",
    "{token.head.text = }\n",
    "{token.dep_ = }\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ef828f0abefb444f9bf7f8c5c326b52e-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Gus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">piano</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef828f0abefb444f9bf7f8c5c326b52e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.3 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"displacy.render(piano_doc, style=\\\"dep\\\")\";\n                var nbb_formatted_code = \"displacy.render(piano_doc, style=\\\"dep\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(piano_doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'Python', 'working']\n",
      "Python\n",
      "currently\n",
      "['a', 'Python']\n",
      "['working']\n",
      "[a, Python, developer, currently, working, for, a, London, -, based, Fintech, company]\n",
      "time: 8.81 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"one_line_about_text = (\\n    \\\"Gus Proto is a Python developer\\\"\\n    \\\" currently working for a London-based Fintech company\\\"\\n)\\none_line_about_doc = nlp(one_line_about_text)\\n\\n# Extract children of `developer`\\nprint([token.text for token in one_line_about_doc[5].children])\\n\\n\\n# Extract previous neighboring node of `developer`\\nprint (one_line_about_doc[5].nbor(-1))\\n\\n\\n# Extract next neighboring node of `developer`\\nprint (one_line_about_doc[5].nbor())\\n\\n\\n# Extract all tokens on the left of `developer`\\nprint([token.text for token in one_line_about_doc[5].lefts])\\n\\n\\n# Extract tokens on the right of `developer`\\nprint([token.text for token in one_line_about_doc[5].rights])\\n\\n\\n# Print subtree of `developer`\\nprint (list(one_line_about_doc[5].subtree))\";\n                var nbb_formatted_code = \"one_line_about_text = (\\n    \\\"Gus Proto is a Python developer\\\"\\n    \\\" currently working for a London-based Fintech company\\\"\\n)\\none_line_about_doc = nlp(one_line_about_text)\\n\\n# Extract children of `developer`\\nprint([token.text for token in one_line_about_doc[5].children])\\n\\n\\n# Extract previous neighboring node of `developer`\\nprint(one_line_about_doc[5].nbor(-1))\\n\\n\\n# Extract next neighboring node of `developer`\\nprint(one_line_about_doc[5].nbor())\\n\\n\\n# Extract all tokens on the left of `developer`\\nprint([token.text for token in one_line_about_doc[5].lefts])\\n\\n\\n# Extract tokens on the right of `developer`\\nprint([token.text for token in one_line_about_doc[5].rights])\\n\\n\\n# Print subtree of `developer`\\nprint(list(one_line_about_doc[5].subtree))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_line_about_text = (\n",
    "    \"Gus Proto is a Python developer\"\n",
    "    \" currently working for a London-based Fintech company\"\n",
    ")\n",
    "one_line_about_doc = nlp(one_line_about_text)\n",
    "\n",
    "# Extract children of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].children])\n",
    "\n",
    "\n",
    "# Extract previous neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor(-1))\n",
    "\n",
    "\n",
    "# Extract next neighboring node of `developer`\n",
    "print (one_line_about_doc[5].nbor())\n",
    "\n",
    "\n",
    "# Extract all tokens on the left of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].lefts])\n",
    "\n",
    "\n",
    "# Extract tokens on the right of `developer`\n",
    "print([token.text for token in one_line_about_doc[5].rights])\n",
    "\n",
    "\n",
    "# Print subtree of `developer`\n",
    "print (list(one_line_about_doc[5].subtree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a developer conference\n",
      "21 July\n",
      "London\n",
      "time: 7.62 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"conference_text = (\\n    \\\"There is a developer conference happening on 21 July 2019 in London.\\\"\\n)\\nconference_doc = nlp(conference_text)\\n\\n# Extract Noun Phrases\\nfor chunk in conference_doc.noun_chunks:\\n    print (chunk)\";\n                var nbb_formatted_code = \"conference_text = \\\"There is a developer conference happening on 21 July 2019 in London.\\\"\\nconference_doc = nlp(conference_text)\\n\\n# Extract Noun Phrases\\nfor chunk in conference_doc.noun_chunks:\\n    print(chunk)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conference_text = (\n",
    "    \"There is a developer conference happening on 21 July 2019 in London.\"\n",
    ")\n",
    "conference_doc = nlp(conference_text)\n",
    "\n",
    "# Extract Noun Phrases\n",
    "for chunk in conference_doc.noun_chunks:\n",
    "    print (chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will introduce\n",
      "The talk\n",
      "reader\n",
      "cases\n",
      "Natural Language Processing\n",
      "Fintech\n",
      "use\n",
      "interesting examples\n",
      "the way\n",
      "time: 605 ms (started: 2023-01-06 14:07:51 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# import textacy\\n\\nabout_talk_text = (\\n    \\\"The talk will introduce reader about use\\\"\\n    \\\" cases of Natural Language Processing in\\\"\\n    \\\" Fintech, making use of\\\"\\n    \\\" interesting examples along the way.\\\"\\n)\\n\\npatterns = [{\\\"POS\\\": \\\"AUX\\\"}, {\\\"POS\\\": \\\"VERB\\\"}]\\nabout_talk_doc = textacy.make_spacy_doc(\\n    about_talk_text, lang=\\\"en_core_web_sm\\\"\\n)\\nverb_phrases = textacy.extract.token_matches(\\n    about_talk_doc, patterns=patterns\\n)\\n\\n# Print all verb phrases\\nfor chunk in verb_phrases:\\n    print(chunk.text)\\n\\n# Extract noun phrase to explain what nouns are involved\\nfor chunk in about_talk_doc.noun_chunks:\\n    print (chunk)\";\n                var nbb_formatted_code = \"# import textacy\\n\\nabout_talk_text = (\\n    \\\"The talk will introduce reader about use\\\"\\n    \\\" cases of Natural Language Processing in\\\"\\n    \\\" Fintech, making use of\\\"\\n    \\\" interesting examples along the way.\\\"\\n)\\n\\npatterns = [{\\\"POS\\\": \\\"AUX\\\"}, {\\\"POS\\\": \\\"VERB\\\"}]\\nabout_talk_doc = textacy.make_spacy_doc(about_talk_text, lang=\\\"en_core_web_sm\\\")\\nverb_phrases = textacy.extract.token_matches(about_talk_doc, patterns=patterns)\\n\\n# Print all verb phrases\\nfor chunk in verb_phrases:\\n    print(chunk.text)\\n\\n# Extract noun phrase to explain what nouns are involved\\nfor chunk in about_talk_doc.noun_chunks:\\n    print(chunk)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import textacy\n",
    "\n",
    "about_talk_text = (\n",
    "    \"The talk will introduce reader about use\"\n",
    "    \" cases of Natural Language Processing in\"\n",
    "    \" Fintech, making use of\"\n",
    "    \" interesting examples along the way.\"\n",
    ")\n",
    "\n",
    "patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "about_talk_doc = textacy.make_spacy_doc(\n",
    "    about_talk_text, lang=\"en_core_web_sm\"\n",
    ")\n",
    "verb_phrases = textacy.extract.token_matches(\n",
    "    about_talk_doc, patterns=patterns\n",
    ")\n",
    "\n",
    "# Print all verb phrases\n",
    "for chunk in verb_phrases:\n",
    "    print(chunk.text)\n",
    "\n",
    "# Extract noun phrase to explain what nouns are involved\n",
    "for chunk in about_talk_doc.noun_chunks:\n",
    "    print (chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ent.text = 'Great Piano Academy'\n",
      "ent.start_char = 0\n",
      "ent.end_char = 19\n",
      "ent.label_ = 'ORG'\n",
      "spacy.explain('ORG') = Companies, agencies, institutions, etc.\n",
      "\n",
      "ent.text = 'Mayfair'\n",
      "ent.start_char = 35\n",
      "ent.end_char = 42\n",
      "ent.label_ = 'LOC'\n",
      "spacy.explain('LOC') = Non-GPE locations, mountain ranges, bodies of water\n",
      "\n",
      "ent.text = 'the City of London'\n",
      "ent.start_char = 46\n",
      "ent.end_char = 64\n",
      "ent.label_ = 'GPE'\n",
      "spacy.explain('GPE') = Countries, cities, states\n",
      "time: 9.64 ms (started: 2023-01-06 14:07:52 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"piano_class_text = (\\n    \\\"Great Piano Academy is situated\\\"\\n    \\\" in Mayfair or the City of London and has\\\"\\n    \\\" world-class piano instructors.\\\"\\n)\\npiano_class_doc = nlp(piano_class_text)\\n\\nfor ent in piano_class_doc.ents:\\n    print(\\n        f\\\"\\\"\\\"\\n{ent.text = }\\n{ent.start_char = }\\n{ent.end_char = }\\n{ent.label_ = }\\nspacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\\\"\\\"\\\"\\n)\";\n                var nbb_formatted_code = \"piano_class_text = (\\n    \\\"Great Piano Academy is situated\\\"\\n    \\\" in Mayfair or the City of London and has\\\"\\n    \\\" world-class piano instructors.\\\"\\n)\\npiano_class_doc = nlp(piano_class_text)\\n\\nfor ent in piano_class_doc.ents:\\n    print(\\n        f\\\"\\\"\\\"\\n{ent.text = }\\n{ent.start_char = }\\n{ent.end_char = }\\n{ent.label_ = }\\nspacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\\\"\\\"\\\"\\n    )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "piano_class_text = (\n",
    "    \"Great Piano Academy is situated\"\n",
    "    \" in Mayfair or the City of London and has\"\n",
    "    \" world-class piano instructors.\"\n",
    ")\n",
    "piano_class_doc = nlp(piano_class_text)\n",
    "\n",
    "for ent in piano_class_doc.ents:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "{ent.text = }\n",
    "{ent.start_char = }\n",
    "{ent.end_char = }\n",
    "{ent.label_ = }\n",
    "spacy.explain('{ent.label_}') = {spacy.explain(ent.label_)}\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Great Piano Academy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is situated in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mayfair\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the City of London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and has world-class piano instructors.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.6 ms (started: 2023-01-06 14:07:52 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"displacy.render(piano_class_doc, style=\\\"ent\\\")\";\n                var nbb_formatted_code = \"displacy.render(piano_class_doc, style=\\\"ent\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(piano_class_doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 5 people surveyed, [REDACTED] , [REDACTED] and [REDACTED] like apples. [REDACTED] and [REDACTED] like oranges.\n",
      "time: 12.1 ms (started: 2023-01-06 14:07:52 +01:00)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 42;\n                var nbb_unformatted_code = \"survey_text = (\\n    \\\"Out of 5 people surveyed, James Robert,\\\"\\n    \\\" Julie Fuller and Benjamin Brooks like\\\"\\n    \\\" apples. Kelly Cox and Matthew Evans\\\"\\n    \\\" like oranges.\\\"\\n)\\n\\n\\ndef replace_person_names(token):\\n    if token.ent_iob != 0 and token.ent_type_ == \\\"PERSON\\\":\\n        return \\\"[REDACTED] \\\"\\n    return token.text_with_ws\\n\\n\\ndef redact_names(nlp_doc):\\n    with nlp_doc.retokenize() as retokenizer:\\n        for ent in nlp_doc.ents:\\n            retokenizer.merge(ent)\\n    tokens = map(replace_person_names, nlp_doc)\\n    return \\\"\\\".join(tokens)\\n\\n\\nsurvey_doc = nlp(survey_text)\\nprint(redact_names(survey_doc))\";\n                var nbb_formatted_code = \"survey_text = (\\n    \\\"Out of 5 people surveyed, James Robert,\\\"\\n    \\\" Julie Fuller and Benjamin Brooks like\\\"\\n    \\\" apples. Kelly Cox and Matthew Evans\\\"\\n    \\\" like oranges.\\\"\\n)\\n\\n\\ndef replace_person_names(token):\\n    if token.ent_iob != 0 and token.ent_type_ == \\\"PERSON\\\":\\n        return \\\"[REDACTED] \\\"\\n    return token.text_with_ws\\n\\n\\ndef redact_names(nlp_doc):\\n    with nlp_doc.retokenize() as retokenizer:\\n        for ent in nlp_doc.ents:\\n            retokenizer.merge(ent)\\n    tokens = map(replace_person_names, nlp_doc)\\n    return \\\"\\\".join(tokens)\\n\\n\\nsurvey_doc = nlp(survey_text)\\nprint(redact_names(survey_doc))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survey_text = (\n",
    "    \"Out of 5 people surveyed, James Robert,\"\n",
    "    \" Julie Fuller and Benjamin Brooks like\"\n",
    "    \" apples. Kelly Cox and Matthew Evans\"\n",
    "    \" like oranges.\"\n",
    ")\n",
    "\n",
    "\n",
    "def replace_person_names(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        return \"[REDACTED] \"\n",
    "    return token.text_with_ws\n",
    "\n",
    "\n",
    "def redact_names(nlp_doc):\n",
    "    with nlp_doc.retokenize() as retokenizer:\n",
    "        for ent in nlp_doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    tokens = map(replace_person_names, nlp_doc)\n",
    "    return \"\".join(tokens)\n",
    "\n",
    "\n",
    "survey_doc = nlp(survey_text)\n",
    "print(redact_names(survey_doc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dcd39a1a4fd5d1ce925d3608d51b40b2a0714e33960bbfca83a9d0704a93f2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
